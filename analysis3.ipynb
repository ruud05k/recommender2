{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34897938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b46f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'archive(3)/'\n",
    "df_books = pd.read_csv(base_dir + 'Books.csv', low_memory=False)\n",
    "df_users = pd.read_csv(base_dir + 'Users.csv', low_memory=False)\n",
    "df_ratings = pd.read_csv(base_dir + 'Ratings.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61db8b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f569bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685d5c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e60bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. ratings:  1149780\n",
      "No. users:  105283\n",
      "No. books:  340556\n"
     ]
    }
   ],
   "source": [
    "print('No. ratings: ', df_ratings.shape[0])\n",
    "print('No. users: ', len(set(df_ratings['User-ID'])))\n",
    "print('No. books: ', len(set(df_ratings['ISBN'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a3e11",
   "metadata": {},
   "source": [
    "### No. NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbea7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_books\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no. non-NAs</th>\n",
       "      <th>no. NAs</th>\n",
       "      <th>NA fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <td>271360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book-Title</th>\n",
       "      <td>271360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book-Author</th>\n",
       "      <td>271359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <td>271360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Publisher</th>\n",
       "      <td>271358</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-URL-S</th>\n",
       "      <td>271360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-URL-M</th>\n",
       "      <td>271360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image-URL-L</th>\n",
       "      <td>271357</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     no. non-NAs  no. NAs  NA fraction\n",
       "ISBN                      271360        0     0.000000\n",
       "Book-Title                271360        0     0.000000\n",
       "Book-Author               271359        1     0.000004\n",
       "Year-Of-Publication       271360        0     0.000000\n",
       "Publisher                 271358        2     0.000007\n",
       "Image-URL-S               271360        0     0.000000\n",
       "Image-URL-M               271360        0     0.000000\n",
       "Image-URL-L               271357        3     0.000011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_books_nas = pd.DataFrame([(~df_books.isnull()).sum(), \n",
    "                              df_books.isnull().sum()], index=['no. non-NAs', 'no. NAs']).transpose()\n",
    "df_books_nas['NA fraction'] = df_books_nas['no. NAs'] / (df_books_nas['no. NAs'] + df_books_nas['no. non-NAs'])\n",
    "\n",
    "print('df_books')\n",
    "display(df_books_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de48d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no. non-NAs</th>\n",
       "      <th>no. NAs</th>\n",
       "      <th>NA fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <td>278858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>278858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>168096</td>\n",
       "      <td>110762</td>\n",
       "      <td>0.397199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          no. non-NAs  no. NAs  NA fraction\n",
       "User-ID        278858        0     0.000000\n",
       "Location       278858        0     0.000000\n",
       "Age            168096   110762     0.397199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_users_nas = pd.DataFrame([(~df_users.isnull()).sum(), \n",
    "                              df_users.isnull().sum()], index=['no. non-NAs', 'no. NAs']).transpose()\n",
    "df_users_nas['NA fraction'] = df_users_nas['no. NAs'] / (df_users_nas['no. NAs'] + df_users_nas['no. non-NAs'])\n",
    "\n",
    "print('df_users')\n",
    "display(df_users_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df7ed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ratings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no. non-NAs</th>\n",
       "      <th>no. NAs</th>\n",
       "      <th>NA fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <td>1149780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <td>1149780</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book-Rating</th>\n",
       "      <td>1149780</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             no. non-NAs  no. NAs  NA fraction\n",
       "User-ID          1149780        0          0.0\n",
       "ISBN             1149780        0          NaN\n",
       "Book-Rating      1149780        0          NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratings_nas = pd.DataFrame([(~df_ratings.isnull()).sum(), \n",
    "                              df_ratings.isnull().sum()], index=['no. non-NAs', 'no. NAs']).transpose()\n",
    "df_ratings_nas['NA fraction'] = df_ratings_nas['no. NAs'] / (df_ratings_nas['no. NAs'] + df_users_nas['no. non-NAs'])\n",
    "\n",
    "print('df_ratings')\n",
    "display(df_ratings_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca132684",
   "metadata": {},
   "source": [
    "### Rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c223c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rating_counts = df_ratings['Book-Rating'].value_counts().sort_index()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(rating_counts.index, rating_counts.values)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(11))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6008b",
   "metadata": {},
   "source": [
    "# Explicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a4a5d",
   "metadata": {},
   "source": [
    "### Remove 0-rating from df_ratings and assign to df_implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efe280",
   "metadata": {},
   "source": [
    "0-rating is associated with implicit user feedback, which is not considered in the current section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2736d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save implicit ratings for later reference\n",
    "df_implicit = df_ratings[df_ratings['Book-Rating'] == 0]\n",
    "\n",
    "df_ratings = df_ratings[df_ratings['Book-Rating'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe555086",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5aaee",
   "metadata": {},
   "source": [
    "Use a down-sampled dataset for models below, as some models take very long time and / or memory to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3968cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, BaselineOnly, KNNBasic, SVD, SVDpp, SlopeOne\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e7d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.784341</td>\n",
       "      <td>1.436962</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.006096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.839574</td>\n",
       "      <td>1.494589</td>\n",
       "      <td>0.295143</td>\n",
       "      <td>0.008830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.771677</td>\n",
       "      <td>1.419034</td>\n",
       "      <td>0.260453</td>\n",
       "      <td>0.006752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.765362</td>\n",
       "      <td>1.409265</td>\n",
       "      <td>0.762585</td>\n",
       "      <td>0.008339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.844212</td>\n",
       "      <td>1.488888</td>\n",
       "      <td>0.615038</td>\n",
       "      <td>0.008161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              test_rmse  test_mae  fit_time  test_time\n",
       "BaselineOnly   1.784341  1.436962  0.020005   0.006096\n",
       "KNNBasic       1.839574  1.494589  0.295143   0.008830\n",
       "SVD            1.771677  1.419034  0.260453   0.006752\n",
       "SVDpp          1.765362  1.409265  0.762585   0.008339\n",
       "SlopeOne       1.844212  1.488888  0.615038   0.008161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iSel = np.random.choice(range(df_ratings.shape[0]), int(1e4), replace=False)\n",
    "df_ratings_sampled = df_ratings.iloc[iSel, :].copy()\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "sf = Dataset.load_from_df(df_ratings_sampled, reader)\n",
    "\n",
    "results = []\n",
    "modelNames = ['BaselineOnly', 'KNNBasic', 'SVD', 'SVDpp', 'SlopeOne']\n",
    "for (i, model) in enumerate([BaselineOnly(), KNNBasic(), SVD(), SVDpp(), SlopeOne()]):\n",
    "    #model.fit(train)\n",
    "    result = cross_validate(model, sf, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=False)\n",
    "    results.append(pd.DataFrame(result).mean(axis=0))\n",
    "    \n",
    "display(pd.DataFrame(results, index=modelNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a006557",
   "metadata": {},
   "source": [
    "SVD and SVDpp perform best. However, SVDpp can also consider implicit feedback (such as click actions and other iteractions). The current dataset only contains explicit feedback (user ratings), such that SVDpp might not offer substantial improvements for this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df2e01",
   "metadata": {},
   "source": [
    "### Matrix factorization (SVD) model training on full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9886bb",
   "metadata": {},
   "source": [
    "Use SVD on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd52235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.641659</td>\n",
       "      <td>1.267452</td>\n",
       "      <td>11.563297</td>\n",
       "      <td>0.482409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_rmse  test_mae   fit_time  test_time\n",
       "SVD   1.641659  1.267452  11.563297   0.482409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "sf = Dataset.load_from_df(df_ratings, reader)\n",
    "\n",
    "results = []\n",
    "modelNames = ['SVD']\n",
    "for (i, model) in enumerate([SVD()]):\n",
    "    result = cross_validate(model, sf, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=False)\n",
    "    results.append(pd.DataFrame(result).mean(axis=0))\n",
    "    \n",
    "display(pd.DataFrame(results, index=modelNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8377449",
   "metadata": {},
   "source": [
    "### Merge user, book, and rating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2eb8901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/052165615X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/052165615X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/052165615X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0521795028.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0521795028.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0521795028.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>http://images.amazon.com/images/P/0060517794.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060517794.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060517794.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>276747</td>\n",
       "      <td>0671537458</td>\n",
       "      <td>9</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Terry McMillan</td>\n",
       "      <td>1995</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/0671537458.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0671537458.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0671537458.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>276747</td>\n",
       "      <td>0679776818</td>\n",
       "      <td>8</td>\n",
       "      <td>iowa city, iowa, usa</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Birdsong: A Novel of Love and War</td>\n",
       "      <td>Sebastian Faulks</td>\n",
       "      <td>1997</td>\n",
       "      <td>Vintage Books USA</td>\n",
       "      <td>http://images.amazon.com/images/P/0679776818.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0679776818.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0679776818.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating              Location   Age  \\\n",
       "1   276729  052165615X            3  rijeka, n/a, croatia  16.0   \n",
       "2   276729  0521795028            6  rijeka, n/a, croatia  16.0   \n",
       "7   276747  0060517794            9  iowa city, iowa, usa  25.0   \n",
       "8   276747  0671537458            9  iowa city, iowa, usa  25.0   \n",
       "9   276747  0679776818            8  iowa city, iowa, usa  25.0   \n",
       "\n",
       "                                          Book-Title       Book-Author  \\\n",
       "1                                     Help!: Level 1     Philip Prowse   \n",
       "2  The Amsterdam Connection : Level 4 (Cambridge ...       Sue Leather   \n",
       "7                           Little Altars Everywhere     Rebecca Wells   \n",
       "8                                  Waiting to Exhale    Terry McMillan   \n",
       "9                  Birdsong: A Novel of Love and War  Sebastian Faulks   \n",
       "\n",
       "   Year-Of-Publication                   Publisher  \\\n",
       "1                 1999  Cambridge University Press   \n",
       "2                 2001  Cambridge University Press   \n",
       "7                 2003                 HarperTorch   \n",
       "8                 1995                      Pocket   \n",
       "9                 1997           Vintage Books USA   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "1  http://images.amazon.com/images/P/052165615X.0...   \n",
       "2  http://images.amazon.com/images/P/0521795028.0...   \n",
       "7  http://images.amazon.com/images/P/0060517794.0...   \n",
       "8  http://images.amazon.com/images/P/0671537458.0...   \n",
       "9  http://images.amazon.com/images/P/0679776818.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "1  http://images.amazon.com/images/P/052165615X.0...   \n",
       "2  http://images.amazon.com/images/P/0521795028.0...   \n",
       "7  http://images.amazon.com/images/P/0060517794.0...   \n",
       "8  http://images.amazon.com/images/P/0671537458.0...   \n",
       "9  http://images.amazon.com/images/P/0679776818.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "1  http://images.amazon.com/images/P/052165615X.0...  \n",
       "2  http://images.amazon.com/images/P/0521795028.0...  \n",
       "7  http://images.amazon.com/images/P/0060517794.0...  \n",
       "8  http://images.amazon.com/images/P/0671537458.0...  \n",
       "9  http://images.amazon.com/images/P/0679776818.0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create merged dataset\n",
    "df_merged = df_ratings.merge(df_users, how='left', on='User-ID')\n",
    "df_merged = df_merged.merge(df_books, how='left', on='ISBN')\n",
    "\n",
    "# drop rows in case there any other missing values\n",
    "df_merged.dropna(inplace=True) \n",
    "\n",
    "# convert year of publication to numeric\n",
    "df_merged['Year-Of-Publication'] = pd.to_numeric(df_merged['Year-Of-Publication'])\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6383d",
   "metadata": {},
   "source": [
    "### Two tower neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5c68f",
   "metadata": {},
   "source": [
    "##### Define Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed8b4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# distinguish user and item features, as well as categorical and continuous features\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, X_item_cat, X_item_cont, X_user_cat, X_user_cont, y):    \n",
    "        self.X_item_cat = X_item_cat\n",
    "        self.X_item_cont = X_item_cont\n",
    "        self.X_user_cat = X_user_cat\n",
    "        self.X_user_cont = X_user_cont        \n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x_item_cat = self.X_item_cat[i]        \n",
    "        x_item_cont = self.X_item_cont[i]   \n",
    "        x_user_cat = self.X_user_cat[i]        \n",
    "        x_user_cont = self.X_user_cont[i]            \n",
    "        y = self.y[i]\n",
    "        \n",
    "        return {\n",
    "            \"x_item_cat\": torch.tensor(x_item_cat, dtype = torch.long),\n",
    "            \"x_item_cont\": torch.tensor(x_item_cont, dtype = torch.float),  \n",
    "            \"x_user_cat\": torch.tensor(x_user_cat, dtype = torch.long),\n",
    "            \"x_user_cont\": torch.tensor(x_user_cont, dtype = torch.float),               \n",
    "            \"y\": torch.tensor(y, dtype = torch.float)\n",
    "        }\n",
    "\n",
    "# select continuous and categorical features for items and users\n",
    "item_cat_features = [\n",
    "    'ISBN',  \n",
    "    'Book-Author',\n",
    "]\n",
    "item_cont_features = [\n",
    "    'Year-Of-Publication',\n",
    "]\n",
    "user_cont_features = [\n",
    "    'Age', \n",
    "]\n",
    "user_cat_features = [\n",
    "    'User-ID',\n",
    "    'Location',\n",
    "]\n",
    "\n",
    "# generate an id for each categorical value\n",
    "for cat_feature in item_cat_features + user_cat_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_merged[cat_feature])\n",
    "    df_merged[cat_feature] = le.transform(df_merged[cat_feature])\n",
    "\n",
    "# continuous feature scaling\n",
    "for cont_feature in item_cont_features + user_cont_features:\n",
    "    mn = np.mean(df_merged[cont_feature])\n",
    "    stddev = np.std(df_merged[cont_feature])\n",
    "    df_merged[cont_feature] = (df_merged[cont_feature] - mn) / stddev\n",
    "    \n",
    "# Split the data into training and testing sets\n",
    "df_train, df_test = train_test_split(df_merged, test_size=0.2, random_state=42)\n",
    "\n",
    "# generate training dataset\n",
    "X_item_cat_train = df_train[item_cat_features].values\n",
    "X_item_cont_train = df_train[item_cont_features].values\n",
    "X_user_cat_train = df_train[user_cat_features].values\n",
    "X_user_cont_train = df_train[user_cont_features].values\n",
    "y_train = df_train['Book-Rating'].values\n",
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "trainDataset = BookDataset(X_item_cat_train, X_item_cont_train, \n",
    "                           X_user_cat_train, X_user_cont_train, y_train)\n",
    "\n",
    "# generate test dataset\n",
    "X_item_cat_test = df_test[item_cat_features].values\n",
    "X_item_cont_test = df_test[item_cont_features].values\n",
    "X_user_cat_test = df_test[user_cat_features].values\n",
    "X_user_cont_test = df_test[user_cont_features].values\n",
    "y_test = df_test['Book-Rating'].values\n",
    "y_test = np.reshape(y_test, (-1, 1))\n",
    "testDataset = BookDataset(X_item_cat_test, X_item_cont_test, \n",
    "                          X_user_cat_test, X_user_cont_test, y_test)\n",
    "\n",
    "# define dataloaders and batch size\n",
    "batchSize = 1000\n",
    "numWorkers = 4\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size = batchSize, num_workers = numWorkers)\n",
    "testDataLoader = DataLoader(testDataset, batch_size = batchSize, num_workers = numWorkers)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8575b",
   "metadata": {},
   "source": [
    "##### Define model geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c76e89da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "TwoTowerRecommender(\n",
      "  (bn_user_cont): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn_item_cont): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (user_embeds): ModuleList(\n",
      "    (0): Embedding(40544, 50)\n",
      "    (1): Embedding(13254, 50)\n",
      "  )\n",
      "  (item_embeds): ModuleList(\n",
      "    (0): Embedding(119945, 50)\n",
      "    (1): Embedding(50883, 50)\n",
      "  )\n",
      "  (user_fc1): Linear(in_features=101, out_features=128, bias=True)\n",
      "  (user_bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (user_dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (user_fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (user_bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (user_dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (item_fc1): Linear(in_features=101, out_features=128, bias=True)\n",
      "  (item_bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (item_dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (item_fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (item_bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (item_dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TwoTowerRecommender(nn.Module):\n",
    "    def __init__(self, user_emb_szs, item_emb_szs, n_user_cont, n_item_cont, \n",
    "                 dropout_prob=0.5):\n",
    "        super(TwoTowerRecommender, self).__init__()\n",
    "\n",
    "        self.n_user_cont = n_user_cont\n",
    "        self.n_item_cont = n_item_cont        \n",
    "        \n",
    "        # batch normalization on continuous features\n",
    "        self.bn_user_cont = nn.BatchNorm1d(n_user_cont)                    \n",
    "        self.bn_item_cont = nn.BatchNorm1d(n_item_cont)                          \n",
    "        \n",
    "        # embedding vectors for categorical features\n",
    "        self.user_embeds = nn.ModuleList([nn.Embedding(ni, nf) for (ni, nf) in user_emb_szs])\n",
    "        self.item_embeds = nn.ModuleList([nn.Embedding(ni, nf) for (ni, nf) in item_emb_szs])\n",
    "        n_user_emb = sum(e.embedding_dim for e in self.user_embeds)\n",
    "        n_item_emb = sum(e.embedding_dim for e in self.item_embeds)\n",
    "        self.n_user_emb = n_user_emb\n",
    "        self.n_item_emb = n_item_emb\n",
    "\n",
    "        # MLP for user tower, use batch normalization and dropout\n",
    "        self.user_fc1 = nn.Linear(n_user_emb + n_user_cont, 128)\n",
    "        self.user_bn1 = nn.BatchNorm1d(128)\n",
    "        self.user_dropout1 = nn.Dropout(dropout_prob)  \n",
    "        self.user_fc2 = nn.Linear(128, 64)\n",
    "        self.user_bn2 = nn.BatchNorm1d(64)\n",
    "        self.user_dropout2 = nn.Dropout(dropout_prob)  \n",
    "\n",
    "        # MLP for item tower, use batch normalization and dropout\n",
    "        self.item_fc1 = nn.Linear(n_item_emb + n_item_cont, 128)\n",
    "        self.item_bn1 = nn.BatchNorm1d(128)\n",
    "        self.item_dropout1 = nn.Dropout(dropout_prob)  \n",
    "        self.item_fc2 = nn.Linear(128, 64)\n",
    "        self.item_bn2 = nn.BatchNorm1d(64)\n",
    "        self.item_dropout2 = nn.Dropout(dropout_prob)  \n",
    "        \n",
    "        # interaction layer\n",
    "        self.fc1 = nn.Linear(64 + 64, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)  \n",
    "        self.output_layer = nn.Linear(64, 1)        \n",
    "        \n",
    "    def forward(self, x_item_cat, x_item_cont, x_user_cat, x_user_cont):        \n",
    "        \n",
    "        if self.n_user_emb != 0:\n",
    "            x_user = [e(x_user_cat[:, i]) for (i, e) in enumerate(self.user_embeds)]           \n",
    "            x_user = torch.cat(x_user, 1)  \n",
    "        if self.n_user_cont != 0:  \n",
    "            x_user_cont = self.bn_user_cont(x_user_cont)            \n",
    "            x_user = torch.cat([x_user, x_user_cont], 1) if self.n_user_emb != 0 else x_user_cont\n",
    "    \n",
    "        if self.n_item_emb != 0:\n",
    "            x_item = [e(x_item_cat[:, i]) for (i, e) in enumerate(self.item_embeds)]           \n",
    "            x_item = torch.cat(x_item, 1)  \n",
    "        if self.n_item_cont != 0:  \n",
    "            x_item_cont = self.bn_item_cont(x_item_cont)                        \n",
    "            x_item = torch.cat([x_item, x_item_cont], 1) if self.n_item_emb != 0 else x_item_cont\n",
    "            \n",
    "        # user tower\n",
    "        user_fc1_output = F.relu(self.user_fc1(x_user))\n",
    "        user_fc1_output = self.user_bn1(user_fc1_output)\n",
    "        user_fc1_output = self.user_dropout1(user_fc1_output)\n",
    "        user_fc2_output = F.relu(self.user_fc2(user_fc1_output))         \n",
    "        user_fc2_output = self.user_bn2(user_fc2_output)\n",
    "        user_fc2_output = self.user_dropout2(user_fc2_output)\n",
    "     \n",
    "        # item tower\n",
    "        item_fc1_output = F.relu(self.item_fc1(x_item))\n",
    "        item_fc1_output = self.item_bn1(item_fc1_output)\n",
    "        item_fc1_output = self.item_dropout1(item_fc1_output)\n",
    "        item_fc2_output = F.relu(self.item_fc2(item_fc1_output))         \n",
    "        item_fc2_output = self.item_bn2(item_fc2_output)\n",
    "        item_fc2_output = self.item_dropout2(item_fc2_output)    \n",
    "\n",
    "        # concatenate and interaction layer\n",
    "        concatenated = torch.cat((user_fc2_output, item_fc2_output), dim=1)\n",
    "        fc1_output = F.relu(self.fc1(concatenated))\n",
    "        fc1_output = self.bn1(fc1_output)\n",
    "        fc1_output = self.dropout1(fc1_output)  \n",
    "        fc2_output = F.relu(self.fc2(fc1_output))\n",
    "        fc2_output = self.bn2(fc2_output)\n",
    "        fc2_output = self.dropout2(fc2_output)  \n",
    "        output = self.output_layer(fc2_output)\n",
    "        return output    \n",
    "\n",
    "# use GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)    \n",
    "    \n",
    "# determine categorical feature cardinalities for use with embedding vectors\n",
    "# use embedding vectors of size 50\n",
    "user_cardins = [len(set(df_merged[cat_feature])) + 1 for cat_feature in user_cat_features]\n",
    "item_cardins = [len(set(df_merged[cat_feature])) + 1 for cat_feature in item_cat_features]\n",
    "user_embeddingSizes = len(user_cat_features) * [50]\n",
    "item_embeddingSizes = len(item_cat_features) * [50]\n",
    "user_emb_szs = list(zip(user_cardins, user_embeddingSizes))\n",
    "item_emb_szs = list(zip(item_cardins, item_embeddingSizes))\n",
    "\n",
    "# determine number of continuous features\n",
    "n_user_cont = len(user_cont_features)\n",
    "n_item_cont = len(item_cont_features)\n",
    "\n",
    "# Initialize the model\n",
    "model = TwoTowerRecommender(user_emb_szs, item_emb_szs, n_user_cont, n_item_cont, \n",
    "                            dropout_prob=0.0)\n",
    "model = model.to(device)\n",
    "\n",
    "# Use MSE loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use Adam optmizer\n",
    "# weight_decay is for L2 regularization\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219a306",
   "metadata": {},
   "source": [
    "##### Set up training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99261249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88042a07db949e3a569485daa5b421e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS epoch  0 :  8.089556\n",
      "LOSS epoch  1 :  2.9896932\n",
      "LOSS epoch  2 :  2.8218842\n",
      "LOSS epoch  3 :  2.7311108\n",
      "LOSS epoch  4 :  2.6957383\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nEpochs = 5\n",
    "\n",
    "progressBar = tqdm(range(nEpochs * len(trainDataLoader)))\n",
    "losses = []\n",
    "for epochIdx in range(nEpochs): \n",
    "    \n",
    "    for batchIdx, d in enumerate(trainDataLoader):   \n",
    "        x_user_cat = d['x_user_cat']\n",
    "        x_user_cont = d['x_user_cont']        \n",
    "        x_item_cat = d['x_item_cat']\n",
    "        x_item_cont = d['x_item_cont']\n",
    "        y = d['y']    \n",
    "        \n",
    "        x_user_cat = x_user_cat.to(device=device)\n",
    "        x_user_cont = x_user_cont.to(device=device)\n",
    "        x_item_cat = x_item_cat.to(device=device)\n",
    "        x_item_cont = x_item_cont.to(device=device)\n",
    "        y = y.to(device=device)   \n",
    "        \n",
    "        # forward propagation\n",
    "        pred = model(x_item_cat, x_item_cont, x_user_cat, x_user_cont)        \n",
    "        \n",
    "        loss = criterion.forward(pred, y)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        if (batchIdx + 1) % len(trainDataLoader) == 0:\n",
    "            print('LOSS epoch ', epochIdx, ': ', np.mean(losses))\n",
    "            losses = []\n",
    "            \n",
    "        # reset previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent \n",
    "        optimizer.step()\n",
    "        \n",
    "        progressBar.update(1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e687146",
   "metadata": {},
   "source": [
    "##### Apply trained model on hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7785f45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c084dc8fcb446aa603f414ad2198fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progressBar = tqdm(range(len(testDataLoader)))\n",
    "preds = np.array([[]])\n",
    "\n",
    "for batchIdx, d in enumerate(testDataLoader):\n",
    "    x_user_cat = d['x_user_cat']\n",
    "    x_user_cont = d['x_user_cont']        \n",
    "    x_item_cat = d['x_item_cat']\n",
    "    x_item_cont = d['x_item_cont']\n",
    "    y = d['y'] \n",
    "    \n",
    "    x_user_cat = x_user_cat.to(device=device)\n",
    "    x_user_cont = x_user_cont.to(device=device)\n",
    "    x_item_cat = x_item_cat.to(device=device)\n",
    "    x_item_cont = x_item_cont.to(device=device)  \n",
    "    y = y.to(device=device)       \n",
    "                \n",
    "    pred = model(x_item_cat, x_item_cont, x_user_cat, x_user_cont)        \n",
    "    \n",
    "    pred_np = pred.cpu().detach().numpy()\n",
    "    preds = np.vstack((preds, pred_np)) if preds.size else pred_np\n",
    "    \n",
    "    progressBar.update(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b25db7",
   "metadata": {},
   "source": [
    "##### Calculate RMSE on hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8373ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6317617513368174\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(np.mean((preds - y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27beb5a1",
   "metadata": {},
   "source": [
    "### Discussion and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beade67",
   "metadata": {},
   "source": [
    "Various models were explored for predicting book ratings. These included k-nearest neighbors (KNNBasic), matrix factorization (SVD and SVDpp), item-based collaborative filtering (SlopeOne), and a two-tower neural network. SVD and the two-tower neural network performed best for this dataset.\n",
    "\n",
    "In contrast to SVD, the two-tower neural network can incorporate additional contextual features, such as user age and location. This is especially beneficial for users with limited interaction history, thus partially resolving cold start issues. Further, the neural network architecture is scalable and can easily be parallelized across multiple computational nodes, unlike SVD with its sequential nature.\n",
    "\n",
    "Only explicit user feedback was considered in this section, whereby the task was to predict ratings. In e-commerce environments, implicit user feedback (e.g. clicks) is much more abundant. In the next section, implicit user feedback is analyzed instead. This also means that the task switches to predicting click-through-rate using binary cross entropy as loss function. Alternatively, the ranking could directly be predicted, for example by calculating the probability that item 1 ranks higher than item 2 (using a pair-wise ranking loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86b210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da0c3a19",
   "metadata": {},
   "source": [
    "# Implicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60857054",
   "metadata": {},
   "source": [
    "Implicit feedback (e.g. clicks) is associated with a book rating of 0. Assign label = 1 for all implicitly interacted books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2917c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_implicit_pos = df_implicit\n",
    "\n",
    "# all observed implicit ratings have label 1\n",
    "df_implicit_pos['label'] = 1\n",
    "\n",
    "# remove rating column\n",
    "del df_implicit_pos['Book-Rating'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbc5db",
   "metadata": {},
   "source": [
    "SVDpp can handle implicit feedback alongside explicit ratings, however the algorithm is quite slow on large datasets. Only the two-tower neural network will be evaluated here for implicit data only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78411616",
   "metadata": {},
   "source": [
    "### Negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7105f81",
   "metadata": {},
   "source": [
    "The problem with implicit feedback is, there is no explicit negative feedback. Certain items could be interesting to the user, he just did not interact with it yet. Therefore, we randomly select combinations of users and items that did not interact, assign these as label 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6418b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of positive and negative labels:\n",
      "1    716109\n",
      "0    716103\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# generate random indices for items and users, and create dataframe\n",
    "user_idcs = np.random.choice(df_users.shape[0], size=(df_implicit_pos.shape[0],), replace=True)\n",
    "book_idcs = np.random.choice(df_books.shape[0], size=(df_implicit_pos.shape[0],), replace=True)\n",
    "dict_temp = {'User-ID': df_users.loc[user_idcs, 'User-ID'].reset_index(drop=True),\n",
    "             'ISBN': df_books.loc[book_idcs, 'ISBN'].reset_index(drop=True)}\n",
    "\n",
    "df_implicit_neg = pd.DataFrame(dict_temp)\n",
    "\n",
    "# random users and items might actually have interacted previously, make sure we remove\n",
    "# these entries\n",
    "df_duplicate = pd.merge(df_implicit_pos, df_implicit_neg, on=['User-ID', 'ISBN'], how='inner')\n",
    "df_implicit_neg = df_implicit_neg.append(df_duplicate)\n",
    "df_implicit_neg['duplicated'] = df_implicit_neg.duplicated(subset=['User-ID', 'ISBN'], \n",
    "                                                           keep=False)\n",
    "df_implicit_neg = df_implicit_neg[~df_implicit_neg['duplicated']] \n",
    "del df_implicit_neg['duplicated'] \n",
    "df_implicit_neg['label'] = 0\n",
    "\n",
    "# join dataframes with positive and negative labels\n",
    "df_implicit = df_implicit_pos.append(df_implicit_neg).reset_index(drop=True)\n",
    "\n",
    "# shuffle the rows\n",
    "df_implicit = df_implicit.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('Counts of positive and negative labels:')\n",
    "print(df_implicit['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c013109",
   "metadata": {},
   "source": [
    "### Merge implicit ratings, book, and users dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8524008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>label</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60262</td>\n",
       "      <td>1575667681</td>\n",
       "      <td>1</td>\n",
       "      <td>new york, new york, usa</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Island of Tears</td>\n",
       "      <td>Troy Soos</td>\n",
       "      <td>2002</td>\n",
       "      <td>Kensington Mass Market</td>\n",
       "      <td>http://images.amazon.com/images/P/1575667681.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1575667681.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1575667681.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275970</td>\n",
       "      <td>0767902521</td>\n",
       "      <td>1</td>\n",
       "      <td>pittsburgh, pennsylvania, usa</td>\n",
       "      <td>46.0</td>\n",
       "      <td>A Walk in the Woods: Rediscovering America on ...</td>\n",
       "      <td>Bill Bryson</td>\n",
       "      <td>1999</td>\n",
       "      <td>Broadway Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0767902521.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767902521.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767902521.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227447</td>\n",
       "      <td>0312962258</td>\n",
       "      <td>1</td>\n",
       "      <td>kelseyville, california, usa</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Red Leaves (Red Leaves)</td>\n",
       "      <td>Paullina Simons</td>\n",
       "      <td>1997</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0312962258.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0312962258.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0312962258.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264509</td>\n",
       "      <td>0898866146</td>\n",
       "      <td>0</td>\n",
       "      <td>geneva, french speaking swiss, switzerland</td>\n",
       "      <td>36.0</td>\n",
       "      <td>The Pocket Doctor: A Passport to Healthy Travel</td>\n",
       "      <td>Stephen Bezruchka</td>\n",
       "      <td>1999</td>\n",
       "      <td>Mountaineers Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0898866146.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0898866146.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0898866146.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193664</td>\n",
       "      <td>0304343897</td>\n",
       "      <td>1</td>\n",
       "      <td>cambridge, cambridgeshire, united kingdom</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Scandinavian Cross Stitch Designs</td>\n",
       "      <td>Jana Hauschild Lindberg</td>\n",
       "      <td>1996</td>\n",
       "      <td>Sterling Pub Co Inc</td>\n",
       "      <td>http://images.amazon.com/images/P/0304343897.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0304343897.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0304343897.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  label                                    Location  \\\n",
       "0    60262  1575667681      1                     new york, new york, usa   \n",
       "2   275970  0767902521      1               pittsburgh, pennsylvania, usa   \n",
       "3   227447  0312962258      1                kelseyville, california, usa   \n",
       "4   264509  0898866146      0  geneva, french speaking swiss, switzerland   \n",
       "6   193664  0304343897      1   cambridge, cambridgeshire, united kingdom   \n",
       "\n",
       "    Age                                         Book-Title  \\\n",
       "0  44.0                                    Island of Tears   \n",
       "2  46.0  A Walk in the Woods: Rediscovering America on ...   \n",
       "3  38.0                            Red Leaves (Red Leaves)   \n",
       "4  36.0    The Pocket Doctor: A Passport to Healthy Travel   \n",
       "6  16.0                  Scandinavian Cross Stitch Designs   \n",
       "\n",
       "               Book-Author  Year-Of-Publication               Publisher  \\\n",
       "0                Troy Soos                 2002  Kensington Mass Market   \n",
       "2              Bill Bryson                 1999          Broadway Books   \n",
       "3          Paullina Simons                 1997      St. Martin's Press   \n",
       "4        Stephen Bezruchka                 1999      Mountaineers Books   \n",
       "6  Jana Hauschild Lindberg                 1996     Sterling Pub Co Inc   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/1575667681.0...   \n",
       "2  http://images.amazon.com/images/P/0767902521.0...   \n",
       "3  http://images.amazon.com/images/P/0312962258.0...   \n",
       "4  http://images.amazon.com/images/P/0898866146.0...   \n",
       "6  http://images.amazon.com/images/P/0304343897.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/1575667681.0...   \n",
       "2  http://images.amazon.com/images/P/0767902521.0...   \n",
       "3  http://images.amazon.com/images/P/0312962258.0...   \n",
       "4  http://images.amazon.com/images/P/0898866146.0...   \n",
       "6  http://images.amazon.com/images/P/0304343897.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/1575667681.0...  \n",
       "2  http://images.amazon.com/images/P/0767902521.0...  \n",
       "3  http://images.amazon.com/images/P/0312962258.0...  \n",
       "4  http://images.amazon.com/images/P/0898866146.0...  \n",
       "6  http://images.amazon.com/images/P/0304343897.0...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create merged dataset\n",
    "df_merged = df_implicit.merge(df_users, how='left', on='User-ID')\n",
    "df_merged = df_merged.merge(df_books, how='left', on='ISBN')\n",
    "\n",
    "# drop rows in case there any other missing values\n",
    "df_merged.dropna(inplace=True) \n",
    "\n",
    "# convert year of publication to numeric\n",
    "df_merged['Year-Of-Publication'] = pd.to_numeric(df_merged['Year-Of-Publication'])\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497a02d",
   "metadata": {},
   "source": [
    "### Use the same dataset and dataloader definition as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0546947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# distinguish user and item features, as well as categorical and continuous features\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, X_item_cat, X_item_cont, X_user_cat, X_user_cont, y):    \n",
    "        self.X_item_cat = X_item_cat\n",
    "        self.X_item_cont = X_item_cont\n",
    "        self.X_user_cat = X_user_cat\n",
    "        self.X_user_cont = X_user_cont        \n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x_item_cat = self.X_item_cat[i]        \n",
    "        x_item_cont = self.X_item_cont[i]   \n",
    "        x_user_cat = self.X_user_cat[i]        \n",
    "        x_user_cont = self.X_user_cont[i]            \n",
    "        y = self.y[i]\n",
    "        \n",
    "        return {\n",
    "            \"x_item_cat\": torch.tensor(x_item_cat, dtype = torch.long),\n",
    "            \"x_item_cont\": torch.tensor(x_item_cont, dtype = torch.float),  \n",
    "            \"x_user_cat\": torch.tensor(x_user_cat, dtype = torch.long),\n",
    "            \"x_user_cont\": torch.tensor(x_user_cont, dtype = torch.float),               \n",
    "            \"y\": torch.tensor(y, dtype = torch.float)\n",
    "        }\n",
    "\n",
    "# select continuous and categorical features for items and users\n",
    "item_cat_features = [\n",
    "    'ISBN',  \n",
    "    'Book-Author',\n",
    "]\n",
    "item_cont_features = [\n",
    "    'Year-Of-Publication',\n",
    "]\n",
    "user_cont_features = [\n",
    "    'Age', \n",
    "]\n",
    "user_cat_features = [\n",
    "    'User-ID',\n",
    "    'Location',\n",
    "]\n",
    "\n",
    "# generate an id for each categorical value\n",
    "for cat_feature in item_cat_features + user_cat_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_merged[cat_feature])\n",
    "    df_merged[cat_feature] = le.transform(df_merged[cat_feature])\n",
    "\n",
    "# continuous feature scaling\n",
    "for cont_feature in item_cont_features + user_cont_features:\n",
    "    mn = np.mean(df_merged[cont_feature])\n",
    "    stddev = np.std(df_merged[cont_feature])\n",
    "    df_merged[cont_feature] = (df_merged[cont_feature] - mn) / stddev\n",
    "    \n",
    "# Split the data into training and testing sets\n",
    "df_train, df_test = train_test_split(df_merged, test_size=0.2, random_state=42)\n",
    "\n",
    "# generate training dataset\n",
    "X_item_cat_train = df_train[item_cat_features].values\n",
    "X_item_cont_train = df_train[item_cont_features].values\n",
    "X_user_cat_train = df_train[user_cat_features].values\n",
    "X_user_cont_train = df_train[user_cont_features].values\n",
    "y_train = df_train['label'].values\n",
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "trainDataset = BookDataset(X_item_cat_train, X_item_cont_train, \n",
    "                           X_user_cat_train, X_user_cont_train, y_train)\n",
    "\n",
    "# generate test dataset\n",
    "X_item_cat_test = df_test[item_cat_features].values\n",
    "X_item_cont_test = df_test[item_cont_features].values\n",
    "X_user_cat_test = df_test[user_cat_features].values\n",
    "X_user_cont_test = df_test[user_cont_features].values\n",
    "y_test = df_test['label'].values\n",
    "y_test = np.reshape(y_test, (-1, 1))\n",
    "testDataset = BookDataset(X_item_cat_test, X_item_cont_test, \n",
    "                          X_user_cat_test, X_user_cont_test, y_test)\n",
    "\n",
    "# define dataloaders and batch size\n",
    "batchSize = 1000\n",
    "numWorkers = 4\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size = batchSize, num_workers = numWorkers)\n",
    "testDataLoader = DataLoader(testDataset, batch_size = batchSize, num_workers = numWorkers)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbd0e4",
   "metadata": {},
   "source": [
    "### Use the same model architecture, but using binary cross entropy loss instead of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c1c7d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "TwoTowerRecommender(\n",
      "  (bn_user_cont): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn_item_cont): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (user_embeds): ModuleList(\n",
      "    (0): Embedding(157678, 50)\n",
      "    (1): Embedding(39419, 50)\n",
      "  )\n",
      "  (item_embeds): ModuleList(\n",
      "    (0): Embedding(250917, 50)\n",
      "    (1): Embedding(95330, 50)\n",
      "  )\n",
      "  (user_fc1): Linear(in_features=101, out_features=128, bias=True)\n",
      "  (user_bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (user_dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (user_fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (user_bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (user_dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (item_fc1): Linear(in_features=101, out_features=128, bias=True)\n",
      "  (item_bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (item_dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (item_fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (item_bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (item_dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TwoTowerRecommender(nn.Module):\n",
    "    def __init__(self, user_emb_szs, item_emb_szs, n_user_cont, n_item_cont, \n",
    "                 dropout_prob=0.5):\n",
    "        super(TwoTowerRecommender, self).__init__()\n",
    "\n",
    "        self.n_user_cont = n_user_cont\n",
    "        self.n_item_cont = n_item_cont        \n",
    "        \n",
    "        # batch normalization on continuous features\n",
    "        self.bn_user_cont = nn.BatchNorm1d(n_user_cont)                    \n",
    "        self.bn_item_cont = nn.BatchNorm1d(n_item_cont)                          \n",
    "        \n",
    "        # embedding vectors for categorical features\n",
    "        self.user_embeds = nn.ModuleList([nn.Embedding(ni, nf) for (ni, nf) in user_emb_szs])\n",
    "        self.item_embeds = nn.ModuleList([nn.Embedding(ni, nf) for (ni, nf) in item_emb_szs])\n",
    "        n_user_emb = sum(e.embedding_dim for e in self.user_embeds)\n",
    "        n_item_emb = sum(e.embedding_dim for e in self.item_embeds)\n",
    "        self.n_user_emb = n_user_emb\n",
    "        self.n_item_emb = n_item_emb\n",
    "\n",
    "        # MLP for user tower, use batch normalization and dropout\n",
    "        self.user_fc1 = nn.Linear(n_user_emb + n_user_cont, 128)\n",
    "        self.user_bn1 = nn.BatchNorm1d(128)\n",
    "        self.user_dropout1 = nn.Dropout(dropout_prob)  \n",
    "        self.user_fc2 = nn.Linear(128, 64)\n",
    "        self.user_bn2 = nn.BatchNorm1d(64)\n",
    "        self.user_dropout2 = nn.Dropout(dropout_prob)  \n",
    "\n",
    "        # MLP for item tower, use batch normalization and dropout\n",
    "        self.item_fc1 = nn.Linear(n_item_emb + n_item_cont, 128)\n",
    "        self.item_bn1 = nn.BatchNorm1d(128)\n",
    "        self.item_dropout1 = nn.Dropout(dropout_prob)  \n",
    "        self.item_fc2 = nn.Linear(128, 64)\n",
    "        self.item_bn2 = nn.BatchNorm1d(64)\n",
    "        self.item_dropout2 = nn.Dropout(dropout_prob)  \n",
    "        \n",
    "        # interaction layer\n",
    "        self.fc1 = nn.Linear(64 + 64, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)  \n",
    "        self.output_layer = nn.Linear(64, 1)        \n",
    "        \n",
    "    def forward(self, x_item_cat, x_item_cont, x_user_cat, x_user_cont):        \n",
    "        \n",
    "        if self.n_user_emb != 0:\n",
    "            x_user = [e(x_user_cat[:, i]) for (i, e) in enumerate(self.user_embeds)]           \n",
    "            x_user = torch.cat(x_user, 1)  \n",
    "        if self.n_user_cont != 0:  \n",
    "            x_user_cont = self.bn_user_cont(x_user_cont)            \n",
    "            x_user = torch.cat([x_user, x_user_cont], 1) if self.n_user_emb != 0 else x_user_cont\n",
    "    \n",
    "        if self.n_item_emb != 0:\n",
    "            x_item = [e(x_item_cat[:, i]) for (i, e) in enumerate(self.item_embeds)]           \n",
    "            x_item = torch.cat(x_item, 1)  \n",
    "        if self.n_item_cont != 0:  \n",
    "            x_item_cont = self.bn_item_cont(x_item_cont)                        \n",
    "            x_item = torch.cat([x_item, x_item_cont], 1) if self.n_item_emb != 0 else x_item_cont\n",
    "            \n",
    "        # user tower\n",
    "        user_fc1_output = F.relu(self.user_fc1(x_user))\n",
    "        user_fc1_output = self.user_bn1(user_fc1_output)\n",
    "        user_fc1_output = self.user_dropout1(user_fc1_output)\n",
    "        user_fc2_output = F.relu(self.user_fc2(user_fc1_output))         \n",
    "        user_fc2_output = self.user_bn2(user_fc2_output)\n",
    "        user_fc2_output = self.user_dropout2(user_fc2_output)\n",
    "     \n",
    "        # item tower\n",
    "        item_fc1_output = F.relu(self.item_fc1(x_item))\n",
    "        item_fc1_output = self.item_bn1(item_fc1_output)\n",
    "        item_fc1_output = self.item_dropout1(item_fc1_output)\n",
    "        item_fc2_output = F.relu(self.item_fc2(item_fc1_output))         \n",
    "        item_fc2_output = self.item_bn2(item_fc2_output)\n",
    "        item_fc2_output = self.item_dropout2(item_fc2_output)    \n",
    "\n",
    "        # concatenate and interaction layer\n",
    "        concatenated = torch.cat((user_fc2_output, item_fc2_output), dim=1)\n",
    "        fc1_output = F.relu(self.fc1(concatenated))\n",
    "        fc1_output = self.bn1(fc1_output)\n",
    "        fc1_output = self.dropout1(fc1_output)  \n",
    "        fc2_output = F.relu(self.fc2(fc1_output))\n",
    "        fc2_output = self.bn2(fc2_output)\n",
    "        fc2_output = self.dropout2(fc2_output)  \n",
    "        output = self.output_layer(fc2_output)\n",
    "        return output    \n",
    "\n",
    "# use GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)    \n",
    "    \n",
    "# determine categorical feature cardinalities for use with embedding vectors\n",
    "# use embedding vectors of size 50\n",
    "user_cardins = [len(set(df_merged[cat_feature])) + 1 for cat_feature in user_cat_features]\n",
    "item_cardins = [len(set(df_merged[cat_feature])) + 1 for cat_feature in item_cat_features]\n",
    "user_embeddingSizes = len(user_cat_features) * [50]\n",
    "item_embeddingSizes = len(item_cat_features) * [50]\n",
    "user_emb_szs = list(zip(user_cardins, user_embeddingSizes))\n",
    "item_emb_szs = list(zip(item_cardins, item_embeddingSizes))\n",
    "\n",
    "# determine number of continuous features\n",
    "n_user_cont = len(user_cont_features)\n",
    "n_item_cont = len(item_cont_features)\n",
    "\n",
    "# Initialize the model\n",
    "model = TwoTowerRecommender(user_emb_szs, item_emb_szs, n_user_cont, n_item_cont, \n",
    "                            dropout_prob=0.0)\n",
    "model = model.to(device)\n",
    "\n",
    "# Use binary cross entropy loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# use Adam optmizer\n",
    "# weight_decay is for L2 regularization\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53380c93",
   "metadata": {},
   "source": [
    "### Set up training loop as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da8e88a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3031b319e6144ab1a12c50c4c8176f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3665 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS epoch  0 :  0.44094524\n",
      "LOSS epoch  1 :  0.29316202\n",
      "LOSS epoch  2 :  0.28236452\n",
      "LOSS epoch  3 :  0.2828422\n",
      "LOSS epoch  4 :  0.28208458\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nEpochs = 5\n",
    "\n",
    "progressBar = tqdm(range(nEpochs * len(trainDataLoader)))\n",
    "losses = []\n",
    "for epochIdx in range(nEpochs): \n",
    "    \n",
    "    for batchIdx, d in enumerate(trainDataLoader):   \n",
    "        x_user_cat = d['x_user_cat']\n",
    "        x_user_cont = d['x_user_cont']        \n",
    "        x_item_cat = d['x_item_cat']\n",
    "        x_item_cont = d['x_item_cont']\n",
    "        y = d['y']    \n",
    "        \n",
    "        x_user_cat = x_user_cat.to(device=device)\n",
    "        x_user_cont = x_user_cont.to(device=device)\n",
    "        x_item_cat = x_item_cat.to(device=device)\n",
    "        x_item_cont = x_item_cont.to(device=device)\n",
    "        y = y.to(device=device)   \n",
    "        \n",
    "        # forward propagation\n",
    "        pred = model(x_item_cat, x_item_cont, x_user_cat, x_user_cont)        \n",
    "        \n",
    "        loss = criterion.forward(pred, y)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        if (batchIdx + 1) % len(trainDataLoader) == 0:\n",
    "            print('LOSS epoch ', epochIdx, ': ', np.mean(losses))\n",
    "            losses = []\n",
    "            \n",
    "        # reset previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent \n",
    "        optimizer.step()\n",
    "        \n",
    "        progressBar.update(1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a6496",
   "metadata": {},
   "source": [
    "### Apply trained model on hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09b7382d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fa74ed349146269ab0e893003d1cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progressBar = tqdm(range(len(testDataLoader)))\n",
    "preds = np.array([[]])\n",
    "\n",
    "for batchIdx, d in enumerate(testDataLoader):\n",
    "    x_user_cat = d['x_user_cat']\n",
    "    x_user_cont = d['x_user_cont']        \n",
    "    x_item_cat = d['x_item_cat']\n",
    "    x_item_cont = d['x_item_cont']\n",
    "    y = d['y'] \n",
    "    \n",
    "    x_user_cat = x_user_cat.to(device=device)\n",
    "    x_user_cont = x_user_cont.to(device=device)\n",
    "    x_item_cat = x_item_cat.to(device=device)\n",
    "    x_item_cont = x_item_cont.to(device=device)  \n",
    "    y = y.to(device=device)       \n",
    "                \n",
    "    pred = model(x_item_cat, x_item_cont, x_user_cat, x_user_cont)        \n",
    "    \n",
    "    pred_np = pred.cpu().detach().numpy()\n",
    "    preds = np.vstack((preds, pred_np)) if preds.size else pred_np\n",
    "    \n",
    "    progressBar.update(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b811bfb",
   "metadata": {},
   "source": [
    "### Calculate logloss, ROC-AUC, and PR-AUC on hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc07f191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC:  0.9442982383168375\n",
      "PR-AUC:  0.9545290372348704\n",
      "logloss:  0.29015698259169875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss, average_precision_score\n",
    "\n",
    "# apply sigmoid on NN outputs\n",
    "pred_probs = torch.sigmoid(torch.tensor(preds)).numpy()\n",
    "\n",
    "print('ROC-AUC: ', roc_auc_score(y_test, pred_probs))\n",
    "print('PR-AUC: ', average_precision_score(y_test, pred_probs))\n",
    "print('logloss: ', log_loss(y_test, pred_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44994144",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e1f19",
   "metadata": {},
   "source": [
    "In this section, implicit feedback was modeled. Negative sampling was applied to generate random combinations of users and items that did not interact to serve as zero labels. The same two-tower neural network as before was used, but using binary cross entropy as loss function. On the hold-out test set, good performance was achieved with an ROC-AUC and PR-AUC of 0.94 and 0.95, respectively.\n",
    "\n",
    "With these models, a ranked list of items could be produced for a certain user, whereby the ranking is determined based on the predicted user rating and / or predicted click probability. Both rating and click probabilities could be used for the ranking, for example by using a weighted average. The weights depend on the relative importance of both measures.\n",
    "\n",
    "Instead of predicting click probability and ranking, the ranking could also directly be predicted. If it is known that item1 is more relevant for a user than item2 (for example because the user chose to interact with item1 instead of item2 when both were presented to him earlier), the neural network could be trained by using a pair-wise ranking loss function. Such a model would thereby instead predict the probability that item1 ranks higher than item2. This would be more closely aligned with the final use-case of a producing a ranked list of relevant items personalized to the user. \n",
    "\n",
    "In the above example, item2 (that the user did not interact with) could also be chosen from negative sampling, as was done in this notebook in the implicit feedback section, this is called implicit pair generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceadaa94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551dbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23c9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718479b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
